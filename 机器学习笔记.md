# 1.机器学习 深度学习
## 1.1 概念
机器学习（machine learning，ML）是一类强大的可以从经验中学习的技术。 通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。  
深度学习（deep learning，DL）  
任一调整参数后的程序，我们称为模型（model）  
通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为学习算法（learning algorithm）。  
 在机器学习中，学习（learning）是一个训练模型的过程。 通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。 换句话说，我们用数据训练（train）我们的模型.  

 ![](https://zh.d2l.ai/_images/ml-loop.svg)

首先，我们想让大家更清楚地了解一些核心组件。 无论我们遇到什么类型的机器学习问题，这些组件都将伴随我们左右：

    1. 我们可以学习的数据（data）。

    2. 如何转换数据的模型（model）。

    3. 一个目标函数（objective function），用来量化模型的有效性。

    4. 调整模型参数以优化目标函数的算法（algorithm）。

## 1.2 数据
```
每个数据集由一个个样本（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 样本有时也叫做数据点（data point）或者数据实例（data instance），通常每个样本由一组称为特征（features，或协变量（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为标签（label，或目标（target））。
```

## 1.3 目标函数
在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为目标函数（objective function）。  

损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为训练数据集（training dataset，或称为训练集（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的效能，这里的“新数据集”通常称为测试数据集（test dataset，或称为测试集（test set））。  

将可用数据集分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。  


## 1.4 优化算法
一旦我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，我们接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。 深度学习中，大多流行的优化算法通常基于一种基本方法–梯度下降（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果你仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。

## 1.5 常见机器学习问题和应用
### 1.5.1 监督学习

监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。  

 这是因为在一定程度上，许多重要的任务可以清晰地描述为：在给定一组特定的可用数据的情况下，估计未知事物的概率。
![](https://zh.d2l.ai/_images/supervised-learning.svg)  

1. 回归
2. 分类
3. 标记问题
4. 搜索
5. 推荐系统
6. 序列学习

#### 回归（regression）

判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题  
最小化平方误差损失函数

#### 分类（classification）
这种“哪一个？”的问题叫做分类（classification）问题。 在分类问题中，我们希望模型能够预测样本属于哪个类别（category，正式称为类（class））  
分类问题的常见损失函数被称为交叉熵（cross-entropy）

#### 标记问题
学习预测不相互排斥的类别的问题称为多标签分类（multi-label classification）  

#### 搜索

#### 推荐系统
另一类与搜索和排名相关的问题是推荐系统（recommender system），它的目标是向特定用户进行“个性化”推荐  

#### 序列学习
序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。 具体来说，输入和输出都是可变长度的序列  
1. 标记和解析
2. 自动语音识别
3. 文本到语音
4. 机器翻译
   
### 1.5.2无监督学习
数据中不含有“目标”的机器学习问题为无监督学习（unsupervised learning）  
不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为离线学习（offline learning）。 

当训练和测试数据不同时，最后一个问题提出了分布偏移（distribution shift）的问题。 接下来，我们将简要描述强化学习问题，这是一类明确考虑与环境交互的问题。

### 强化学习（reinforcement learning）
在强化学习问题中，agent在一系列的时间步骤上与环境交互。 在每个特定时间点，agent从环境接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后agent从环境中获得奖励（reward）。 此后新一轮循环开始，agent接收后续观察，并选择后续操作，依此类推。  

请注意，强化学习的目标是产生一个好的策略（policy）。 强化学习agent选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

![](https://zh.d2l.ai/_images/rl-environment.svg)

当环境可被完全观察到时，我们将强化学习问题称为马尔可夫决策过程（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为上下文赌博机（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的多臂赌博机（multi-armed bandit problem）。  








